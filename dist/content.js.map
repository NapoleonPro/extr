{"version":3,"file":"content.js","mappings":";;;;;;;;;;;;;;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACnFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;ACv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sources":["webpack://extr/./src/content/speechRecognition.ts","webpack://extr/webpack/bootstrap","webpack://extr/webpack/runtime/define property getters","webpack://extr/webpack/runtime/hasOwnProperty shorthand","webpack://extr/webpack/runtime/make namespace object","webpack://extr/./src/content/content.ts"],"sourcesContent":["// Speech Recognition Handler\n// File: src/content/speechRecognition.ts\nexport class TranscriptRecognition {\n    constructor(callback) {\n        this.isListening = false;\n        this.transcriptCallback = callback;\n        this.initRecognition();\n    }\n    initRecognition() {\n        // Check if Speech Recognition is supported\n        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n        if (!SpeechRecognition) {\n            console.error('Speech Recognition not supported in this browser');\n            return;\n        }\n        this.recognition = new SpeechRecognition();\n        // Configuration\n        this.recognition.continuous = true; // Keep listening\n        this.recognition.interimResults = true; // Get partial results\n        this.recognition.lang = 'id-ID'; // Bahasa Indonesia (ganti 'en-US' untuk English)\n        this.recognition.maxAlternatives = 1;\n        // Event Handlers\n        this.recognition.onresult = (event) => {\n            this.handleResult(event);\n        };\n        this.recognition.onerror = (event) => {\n            console.error('Speech recognition error:', event.error);\n            // Auto-restart on network error\n            if (event.error === 'network') {\n                console.log('Network error, restarting...');\n                setTimeout(() => this.start(), 1000);\n            }\n        };\n        this.recognition.onend = () => {\n            console.log('Speech recognition ended');\n            // Auto-restart if still supposed to be listening\n            if (this.isListening) {\n                console.log('Auto-restarting recognition...');\n                this.recognition.start();\n            }\n        };\n        console.log('Speech Recognition initialized');\n    }\n    handleResult(event) {\n        // Get the latest result\n        const result = event.results[event.resultIndex];\n        const transcript = result[0].transcript;\n        const confidence = result[0].confidence;\n        const isFinal = result.isFinal;\n        // Send to callback\n        this.transcriptCallback(transcript, isFinal, confidence);\n        // Log for debugging\n        console.log(`[${isFinal ? 'FINAL' : 'INTERIM'}] ${transcript} (confidence: ${confidence?.toFixed(2) || 'N/A'})`);\n    }\n    start() {\n        if (!this.recognition) {\n            console.error('Speech Recognition not initialized');\n            return;\n        }\n        if (this.isListening) {\n            console.log('Already listening');\n            return;\n        }\n        try {\n            this.recognition.start();\n            this.isListening = true;\n            console.log('Started listening...');\n        }\n        catch (error) {\n            console.error('Error starting recognition:', error);\n        }\n    }\n    stop() {\n        if (!this.recognition || !this.isListening) {\n            return;\n        }\n        this.isListening = false;\n        this.recognition.stop();\n        console.log('Stopped listening');\n    }\n    isActive() {\n        return this.isListening;\n    }\n}\n","// The module cache\nvar __webpack_module_cache__ = {};\n\n// The require function\nfunction __webpack_require__(moduleId) {\n\t// Check if module is in cache\n\tvar cachedModule = __webpack_module_cache__[moduleId];\n\tif (cachedModule !== undefined) {\n\t\treturn cachedModule.exports;\n\t}\n\t// Create a new module (and put it into the cache)\n\tvar module = __webpack_module_cache__[moduleId] = {\n\t\t// no module.id needed\n\t\t// no module.loaded needed\n\t\texports: {}\n\t};\n\n\t// Execute the module function\n\t__webpack_modules__[moduleId](module, module.exports, __webpack_require__);\n\n\t// Return the exports of the module\n\treturn module.exports;\n}\n\n","// define getter functions for harmony exports\n__webpack_require__.d = (exports, definition) => {\n\tfor(var key in definition) {\n\t\tif(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n\t\t\tObject.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n\t\t}\n\t}\n};","__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))","// define __esModule on exports\n__webpack_require__.r = (exports) => {\n\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n\t}\n\tObject.defineProperty(exports, '__esModule', { value: true });\n};","// Content Script - Draggable & Resizable Overlay\n// File: src/content/content.ts\nimport { TranscriptRecognition } from './speechRecognition';\nconsole.log('Tab Audio Capture content script loaded!');\nlet recognition = null;\nlet transcriptOverlay = null;\nlet lastProcessedText = '';\nlet displayedTexts = new Set();\nlet transcriptBuffer = [];\nconst BUFFER_CLEANUP_INTERVAL = 30000;\n// Drag & Resize state\nlet isDragging = false;\nlet isResizing = false;\nlet dragStartX = 0;\nlet dragStartY = 0;\nlet overlayStartX = 0;\nlet overlayStartY = 0;\nlet resizeStartWidth = 0;\nlet resizeStartHeight = 0;\nlet resizeStartX = 0;\nlet resizeStartY = 0;\n// Auto-clear state\nlet lastAudioTimestamp = Date.now();\nlet autoClearTimer = null;\nconst AUTO_CLEAR_DELAY = 4000; // 4 detik tanpa suara\nfunction createOverlay() {\n    if (transcriptOverlay)\n        return;\n    transcriptOverlay = document.createElement('div');\n    transcriptOverlay.id = 'transcript-overlay';\n    transcriptOverlay.style.cssText = `\n    position: fixed;\n    bottom: 20px;\n    left: 50%;\n    transform: translateX(-50%);\n    background: #f7f7f7;\n    color: #535353;\n    padding: 0;\n    border-radius: 8px;\n    font-family: system-ui, -apple-system, sans-serif;\n    font-size: 16px;\n    width: 600px;\n    height: 250px;\n    z-index: 999999;\n    box-shadow: 0 8px 0 #535353, 0 8px 32px rgba(0, 0, 0, 0.3);\n    display: none;\n    border: 3px solid #535353;\n    resize: none;\n  `;\n    // Header (draggable area)\n    const headerDiv = document.createElement('div');\n    headerDiv.id = 'transcript-header';\n    headerDiv.style.cssText = `\n    display: flex;\n    justify-content: space-between;\n    align-items: center;\n    padding: 12px 16px;\n    border-bottom: 3px solid #535353;\n    cursor: move;\n    user-select: none;\n    background: white;\n    border-radius: 4px 4px 0 0;\n  `;\n    const statusDiv = document.createElement('div');\n    statusDiv.id = 'transcript-status';\n    statusDiv.style.cssText = `\n    font-size: 11px;\n    color: #535353;\n    display: flex;\n    align-items: center;\n    gap: 8px;\n    font-weight: 600;\n    text-transform: uppercase;\n    letter-spacing: 0.5px;\n  `;\n    statusDiv.innerHTML = `\n    <span style=\"display: inline-block; width: 8px; height: 8px; background: #535353; border-radius: 50%;\"></span>\n    <span id=\"status-text\">LISTENING</span>\n  `;\n    const controlsDiv = document.createElement('div');\n    controlsDiv.style.cssText = `\n    display: flex;\n    gap: 8px;\n    align-items: center;\n  `;\n    // Stop button\n    const stopButton = document.createElement('button');\n    stopButton.id = 'overlay-stop-btn';\n    stopButton.textContent = '‚èπ STOP';\n    stopButton.style.cssText = `\n    padding: 6px 14px;\n    background: white;\n    color: #535353;\n    border: 2px solid #535353;\n    border-radius: 4px;\n    cursor: pointer;\n    font-size: 11px;\n    font-weight: 700;\n    text-transform: uppercase;\n    letter-spacing: 0.5px;\n    box-shadow: 0 3px 0 #535353;\n    position: relative;\n    top: 0;\n    transition: all 0.1s;\n  `;\n    stopButton.addEventListener('mouseenter', () => {\n        stopButton.style.background = '#f0f0f0';\n    });\n    stopButton.addEventListener('mouseleave', () => {\n        stopButton.style.background = 'white';\n    });\n    stopButton.addEventListener('mousedown', () => {\n        stopButton.style.top = '3px';\n        stopButton.style.boxShadow = '0 0 0 #535353';\n    });\n    stopButton.addEventListener('mouseup', () => {\n        stopButton.style.top = '0';\n        stopButton.style.boxShadow = '0 3px 0 #535353';\n    });\n    stopButton.addEventListener('click', () => {\n        if (recognition) {\n            recognition.stop();\n            hideOverlay();\n            resetBuffer();\n            stopAutoClearTimer();\n        }\n    });\n    const audioSourceDiv = document.createElement('div');\n    audioSourceDiv.id = 'audio-source';\n    audioSourceDiv.style.cssText = `\n    font-size: 10px;\n    color: #787878;\n    display: flex;\n    align-items: center;\n    gap: 6px;\n    text-transform: uppercase;\n    letter-spacing: 0.5px;\n  `;\n    // audioSourceDiv.innerHTML = `<span>ü¶ñ</span`;\n    controlsDiv.appendChild(audioSourceDiv);\n    controlsDiv.appendChild(stopButton);\n    headerDiv.appendChild(statusDiv);\n    headerDiv.appendChild(controlsDiv);\n    // Content area (scrollable)\n    const contentDiv = document.createElement('div');\n    contentDiv.id = 'transcript-content';\n    contentDiv.style.cssText = `\n    padding: 16px 20px;\n    overflow-y: auto;\n    height: calc(100% - 100px);\n  `;\n    const textDiv = document.createElement('div');\n    textDiv.id = 'transcript-text';\n    textDiv.style.cssText = `\n    line-height: 1.7;\n    min-height: 32px;\n    color: #535353;\n    letter-spacing: 0.3px;\n  `;\n    textDiv.innerHTML = `<span style=\"color: #787878; font-style: italic;\">Waiting for audio...</span>`;\n    const interimDiv = document.createElement('div');\n    interimDiv.id = 'interim-text';\n    interimDiv.style.cssText = `\n    margin-top: 8px;\n    padding: 8px;\n    background: rgba(83, 83, 83, 0.05);\n    border-radius: 4px;\n    border-left: 3px solid #787878;\n    font-style: italic;\n    color: #787878;\n    font-size: 14px;\n    display: none;\n  `;\n    contentDiv.appendChild(textDiv);\n    contentDiv.appendChild(interimDiv);\n    // Resize handle\n    const resizeHandle = document.createElement('div');\n    resizeHandle.id = 'resize-handle';\n    resizeHandle.style.cssText = `\n    position: absolute;\n    bottom: 0;\n    right: 0;\n    width: 16px;\n    height: 16px;\n    cursor: nwse-resize;\n    background: repeating-linear-gradient(\n      135deg,\n      #535353,\n      #535353 2px,\n      transparent 2px,\n      transparent 4px\n    );\n    border-radius: 0 0 4px 0;\n  `;\n    const style = document.createElement('style');\n    style.textContent = `\n    @keyframes fadeIn {\n      from { opacity: 0; transform: translateY(10px); }\n      to { opacity: 1; transform: translateY(0); }\n    }\n    \n    #transcript-content::-webkit-scrollbar {\n      width: 8px;\n    }\n    \n    #transcript-content::-webkit-scrollbar-track {\n      background: rgba(83, 83, 83, 0.1);\n      border-radius: 4px;\n    }\n    \n    #transcript-content::-webkit-scrollbar-thumb {\n      background: #535353;\n      border-radius: 4px;\n    }\n    \n    .transcript-segment {\n      animation: fadeIn 0.3s ease-out;\n      margin-bottom: 8px;\n    }\n    \n    .repaired-text {\n      background: rgba(83, 83, 83, 0.1);\n      padding: 2px 6px;\n      border-radius: 3px;\n      border-bottom: 2px solid #535353;\n    }\n    \n    .low-confidence {\n      color: #787878;\n    }\n    \n    .medium-confidence {\n      color: #535353;\n    }\n    \n    #transcript-overlay.dragging {\n      cursor: move !important;\n      box-shadow: 0 12px 0 #535353, 0 12px 40px rgba(0, 0, 0, 0.4);\n    }\n    \n    #transcript-overlay.resizing {\n      cursor: nwse-resize !important;\n    }\n  `;\n    document.head.appendChild(style);\n    transcriptOverlay.appendChild(headerDiv);\n    transcriptOverlay.appendChild(contentDiv);\n    transcriptOverlay.appendChild(resizeHandle);\n    document.body.appendChild(transcriptOverlay);\n    // Setup drag & resize\n    setupDragAndResize(headerDiv, resizeHandle);\n    console.log('Enhanced draggable & resizable overlay created');\n    startBufferCleanup();\n}\nfunction setupDragAndResize(header, resizeHandle) {\n    if (!transcriptOverlay)\n        return;\n    // DRAG functionality\n    header.addEventListener('mousedown', (e) => {\n        if (e.target.closest('#resize-handle'))\n            return;\n        if (e.target.closest('#overlay-stop-btn'))\n            return;\n        isDragging = true;\n        transcriptOverlay.classList.add('dragging');\n        dragStartX = e.clientX;\n        dragStartY = e.clientY;\n        const rect = transcriptOverlay.getBoundingClientRect();\n        overlayStartX = rect.left;\n        overlayStartY = rect.top;\n        // Remove transform for absolute positioning\n        transcriptOverlay.style.transform = 'none';\n        transcriptOverlay.style.left = `${overlayStartX}px`;\n        transcriptOverlay.style.top = `${overlayStartY}px`;\n        e.preventDefault();\n    });\n    // RESIZE functionality\n    resizeHandle.addEventListener('mousedown', (e) => {\n        isResizing = true;\n        transcriptOverlay.classList.add('resizing');\n        resizeStartX = e.clientX;\n        resizeStartY = e.clientY;\n        const rect = transcriptOverlay.getBoundingClientRect();\n        resizeStartWidth = rect.width;\n        resizeStartHeight = rect.height;\n        e.preventDefault();\n        e.stopPropagation();\n    });\n    // Global mouse move\n    document.addEventListener('mousemove', (e) => {\n        if (isDragging && transcriptOverlay) {\n            const deltaX = e.clientX - dragStartX;\n            const deltaY = e.clientY - dragStartY;\n            let newX = overlayStartX + deltaX;\n            let newY = overlayStartY + deltaY;\n            // Boundary constraints\n            const maxX = window.innerWidth - transcriptOverlay.offsetWidth;\n            const maxY = window.innerHeight - transcriptOverlay.offsetHeight;\n            newX = Math.max(0, Math.min(newX, maxX));\n            newY = Math.max(0, Math.min(newY, maxY));\n            transcriptOverlay.style.left = `${newX}px`;\n            transcriptOverlay.style.top = `${newY}px`;\n        }\n        if (isResizing && transcriptOverlay) {\n            const deltaX = e.clientX - resizeStartX;\n            const deltaY = e.clientY - resizeStartY;\n            let newWidth = resizeStartWidth + deltaX;\n            let newHeight = resizeStartHeight + deltaY;\n            // Min/max constraints\n            newWidth = Math.max(300, Math.min(newWidth, window.innerWidth - 40));\n            newHeight = Math.max(150, Math.min(newHeight, window.innerHeight - 40));\n            transcriptOverlay.style.width = `${newWidth}px`;\n            transcriptOverlay.style.height = `${newHeight}px`;\n        }\n    });\n    // Global mouse up\n    document.addEventListener('mouseup', () => {\n        if (isDragging) {\n            isDragging = false;\n            transcriptOverlay?.classList.remove('dragging');\n        }\n        if (isResizing) {\n            isResizing = false;\n            transcriptOverlay?.classList.remove('resizing');\n        }\n    });\n}\nfunction startBufferCleanup() {\n    setInterval(() => {\n        const now = Date.now();\n        transcriptBuffer = transcriptBuffer.filter(item => now - item.timestamp < BUFFER_CLEANUP_INTERVAL);\n        if (displayedTexts.size > 50) {\n            displayedTexts.clear();\n        }\n    }, 10000);\n}\nfunction isTextAlreadyDisplayed(newText) {\n    const normalized = newText.toLowerCase().trim();\n    if (displayedTexts.has(normalized)) {\n        return true;\n    }\n    if (lastProcessedText) {\n        const lastNormalized = lastProcessedText.toLowerCase().trim();\n        if (lastNormalized.includes(normalized) && normalized.length > 5) {\n            return true;\n        }\n        const similarity = calculateSimilarity(normalized, lastNormalized);\n        if (similarity > 0.8) {\n            return true;\n        }\n    }\n    return false;\n}\nfunction calculateSimilarity(str1, str2) {\n    const longer = str1.length > str2.length ? str1 : str2;\n    const shorter = str1.length > str2.length ? str2 : str1;\n    if (longer.length === 0)\n        return 1.0;\n    const editDistance = getEditDistance(longer, shorter);\n    return (longer.length - editDistance) / longer.length;\n}\nfunction getEditDistance(str1, str2) {\n    const matrix = [];\n    for (let i = 0; i <= str2.length; i++) {\n        matrix[i] = [i];\n    }\n    for (let j = 0; j <= str1.length; j++) {\n        matrix[0][j] = j;\n    }\n    for (let i = 1; i <= str2.length; i++) {\n        for (let j = 1; j <= str1.length; j++) {\n            if (str2.charAt(i - 1) === str1.charAt(j - 1)) {\n                matrix[i][j] = matrix[i - 1][j - 1];\n            }\n            else {\n                matrix[i][j] = Math.min(matrix[i - 1][j - 1] + 1, matrix[i][j - 1] + 1, matrix[i - 1][j] + 1);\n            }\n        }\n    }\n    return matrix[str2.length][str1.length];\n}\nasync function repairTextWithAI(text, confidence) {\n    try {\n        const statusText = document.getElementById('status-text');\n        if (statusText) {\n            statusText.textContent = 'PROCESSING...';\n        }\n        const requestId = `${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;\n        const response = await Promise.race([\n            chrome.runtime.sendMessage({\n                action: 'repairText',\n                text: text,\n                confidence: confidence,\n                requestId: requestId\n            }),\n            new Promise((_, reject) => setTimeout(() => reject(new Error('Timeout')), 2000))\n        ]);\n        if (statusText) {\n            statusText.textContent = 'LISTENING';\n        }\n        if (response && response.success) {\n            return {\n                text: response.repairedText,\n                wasRepaired: response.wasRepaired\n            };\n        }\n        return { text, wasRepaired: false };\n    }\n    catch (error) {\n        console.warn('AI Repair timeout/error:', error);\n        const statusText = document.getElementById('status-text');\n        if (statusText) {\n            statusText.textContent = 'LISTENING';\n        }\n        return { text, wasRepaired: false };\n    }\n}\nfunction showInterim(text) {\n    const interimDiv = document.getElementById('interim-text');\n    if (!interimDiv)\n        return;\n    if (text && text.length > 2) {\n        interimDiv.textContent = `\"${text}...\"`;\n        interimDiv.style.display = 'block';\n    }\n}\nfunction hideInterim() {\n    const interimDiv = document.getElementById('interim-text');\n    if (interimDiv) {\n        interimDiv.style.display = 'none';\n    }\n}\n// AUTO-CLEAR: Hapus transkrip lama setelah beberapa detik tanpa suara\nfunction resetAutoClearTimer() {\n    // Clear existing timer\n    if (autoClearTimer !== null) {\n        clearTimeout(autoClearTimer);\n    }\n    // Update timestamp\n    lastAudioTimestamp = Date.now();\n    // Set new timer\n    autoClearTimer = window.setTimeout(() => {\n        const textDiv = document.getElementById('transcript-text');\n        if (!textDiv)\n            return;\n        const timeSinceLastAudio = Date.now() - lastAudioTimestamp;\n        // Jika sudah lebih dari AUTO_CLEAR_DELAY tanpa suara baru\n        if (timeSinceLastAudio >= AUTO_CLEAR_DELAY) {\n            console.log('üßπ Auto-clearing old transcripts (no audio for 4s)');\n            // Fade out effect\n            textDiv.style.transition = 'opacity 0.5s ease-out';\n            textDiv.style.opacity = '0';\n            setTimeout(() => {\n                textDiv.innerHTML = '<span style=\"color: #787878; font-style: italic;\">Waiting for audio...</span>';\n                textDiv.style.opacity = '1';\n                // Reset buffers\n                lastProcessedText = '';\n                displayedTexts.clear();\n            }, 500);\n        }\n    }, AUTO_CLEAR_DELAY);\n}\n// Stop auto-clear timer\nfunction stopAutoClearTimer() {\n    if (autoClearTimer !== null) {\n        clearTimeout(autoClearTimer);\n        autoClearTimer = null;\n    }\n}\nasync function updateTranscript(text, isFinal, confidence) {\n    if (!transcriptOverlay)\n        return;\n    // ‚è±Ô∏è Reset timer setiap ada audio baru (interim atau final)\n    resetAutoClearTimer();\n    if (!isFinal) {\n        showInterim(text);\n        return;\n    }\n    hideInterim();\n    const textDiv = document.getElementById('transcript-text');\n    const contentDiv = document.getElementById('transcript-content');\n    if (!textDiv || !contentDiv)\n        return;\n    if (isTextAlreadyDisplayed(text)) {\n        console.log('‚è≠Ô∏è Skipping duplicate text:', text);\n        return;\n    }\n    if (textDiv.innerHTML.includes('Waiting for audio')) {\n        textDiv.innerHTML = '';\n    }\n    const tempId = `temp-${Date.now()}`;\n    const tempSegment = `<span class=\"transcript-segment\" id=\"${tempId}\">${text}</span> `;\n    textDiv.innerHTML += tempSegment;\n    contentDiv.scrollTop = contentDiv.scrollHeight;\n    repairTextWithAI(text, confidence).then(repairResult => {\n        const repairedText = repairResult.text;\n        const wasRepaired = repairResult.wasRepaired;\n        let confidenceClass = '';\n        if (confidence < 0.5) {\n            confidenceClass = 'low-confidence';\n        }\n        else if (confidence < 0.7) {\n            confidenceClass = 'medium-confidence';\n        }\n        const repairClass = wasRepaired ? 'repaired-text' : '';\n        const finalSegment = `<span class=\"transcript-segment ${confidenceClass} ${repairClass}\">${repairedText}</span> `;\n        const tempEl = document.getElementById(tempId);\n        if (tempEl) {\n            tempEl.remove();\n        }\n        textDiv.innerHTML += finalSegment;\n        lastProcessedText = repairedText;\n        displayedTexts.add(repairedText.toLowerCase().trim());\n        transcriptBuffer.push({\n            text: repairedText,\n            timestamp: Date.now()\n        });\n        contentDiv.scrollTop = contentDiv.scrollHeight;\n        const segments = textDiv.querySelectorAll('.transcript-segment');\n        if (segments.length > 10) {\n            for (let i = 0; i < segments.length - 10; i++) {\n                segments[i].remove();\n            }\n        }\n        console.log(`‚úÖ Displayed: \"${text}\" ‚Üí \"${repairedText}\" (conf: ${confidence.toFixed(2)}, repaired: ${wasRepaired})`);\n    });\n}\nfunction showOverlay() {\n    if (transcriptOverlay) {\n        transcriptOverlay.style.display = 'block';\n    }\n}\nfunction hideOverlay() {\n    if (transcriptOverlay) {\n        transcriptOverlay.style.display = 'none';\n    }\n}\nfunction resetBuffer() {\n    lastProcessedText = '';\n    displayedTexts.clear();\n    transcriptBuffer = [];\n    stopAutoClearTimer(); // ‚è±Ô∏è Stop timer saat reset\n}\nchrome.runtime.onMessage.addListener((message, sender, sendResponse) => {\n    console.log(' Message received:', message);\n    if (message.action === 'ping') {\n        sendResponse({ success: true, message: 'Tab audio content script ready' });\n        return true;\n    }\n    if (message.action === 'start') {\n        (async () => {\n            try {\n                createOverlay();\n                resetBuffer();\n                if (!recognition) {\n                    recognition = new TranscriptRecognition(async (text, isFinal, confidence) => {\n                        await updateTranscript(text, isFinal, confidence);\n                    });\n                }\n                recognition.start();\n                showOverlay();\n                sendResponse({ success: true, message: 'Started listening to tab audio' });\n            }\n            catch (error) {\n                console.error('‚ùå Start error:', error);\n                sendResponse({ success: false, message: String(error) });\n            }\n        })();\n        return true;\n    }\n    if (message.action === 'stop') {\n        if (recognition) {\n            recognition.stop();\n            hideOverlay();\n            resetBuffer();\n            stopAutoClearTimer(); // ‚è±Ô∏è Stop timer saat stop\n        }\n        sendResponse({ success: true, message: 'Stopped' });\n        return true;\n    }\n    return true;\n});\n"],"names":[],"sourceRoot":""}