{"version":3,"file":"content.js","mappings":";;;;;;;;;;;;;;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;ACnFA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;ACvBA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;ACPA;;;;;ACAA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;ACNA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","sources":["webpack://extr/./src/content/speechRecognition.ts","webpack://extr/webpack/bootstrap","webpack://extr/webpack/runtime/define property getters","webpack://extr/webpack/runtime/hasOwnProperty shorthand","webpack://extr/webpack/runtime/make namespace object","webpack://extr/./src/content/content.ts"],"sourcesContent":["// Speech Recognition Handler\n// File: src/content/speechRecognition.ts\nexport class TranscriptRecognition {\n    constructor(callback) {\n        this.isListening = false;\n        this.transcriptCallback = callback;\n        this.initRecognition();\n    }\n    initRecognition() {\n        // Check if Speech Recognition is supported\n        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;\n        if (!SpeechRecognition) {\n            console.error('Speech Recognition not supported in this browser');\n            return;\n        }\n        this.recognition = new SpeechRecognition();\n        // Configuration\n        this.recognition.continuous = true; // Keep listening\n        this.recognition.interimResults = true; // Get partial results\n        this.recognition.lang = 'id-ID'; // Bahasa Indonesia (ganti 'en-US' untuk English)\n        this.recognition.maxAlternatives = 1;\n        // Event Handlers\n        this.recognition.onresult = (event) => {\n            this.handleResult(event);\n        };\n        this.recognition.onerror = (event) => {\n            console.error('Speech recognition error:', event.error);\n            // Auto-restart on network error\n            if (event.error === 'network') {\n                console.log('Network error, restarting...');\n                setTimeout(() => this.start(), 1000);\n            }\n        };\n        this.recognition.onend = () => {\n            console.log('Speech recognition ended');\n            // Auto-restart if still supposed to be listening\n            if (this.isListening) {\n                console.log('Auto-restarting recognition...');\n                this.recognition.start();\n            }\n        };\n        console.log('Speech Recognition initialized');\n    }\n    handleResult(event) {\n        // Get the latest result\n        const result = event.results[event.resultIndex];\n        const transcript = result[0].transcript;\n        const confidence = result[0].confidence;\n        const isFinal = result.isFinal;\n        // Send to callback\n        this.transcriptCallback(transcript, isFinal, confidence);\n        // Log for debugging\n        console.log(`[${isFinal ? 'FINAL' : 'INTERIM'}] ${transcript} (confidence: ${confidence?.toFixed(2) || 'N/A'})`);\n    }\n    start() {\n        if (!this.recognition) {\n            console.error('Speech Recognition not initialized');\n            return;\n        }\n        if (this.isListening) {\n            console.log('Already listening');\n            return;\n        }\n        try {\n            this.recognition.start();\n            this.isListening = true;\n            console.log('Started listening...');\n        }\n        catch (error) {\n            console.error('Error starting recognition:', error);\n        }\n    }\n    stop() {\n        if (!this.recognition || !this.isListening) {\n            return;\n        }\n        this.isListening = false;\n        this.recognition.stop();\n        console.log('Stopped listening');\n    }\n    isActive() {\n        return this.isListening;\n    }\n}\n","// The module cache\nvar __webpack_module_cache__ = {};\n\n// The require function\nfunction __webpack_require__(moduleId) {\n\t// Check if module is in cache\n\tvar cachedModule = __webpack_module_cache__[moduleId];\n\tif (cachedModule !== undefined) {\n\t\treturn cachedModule.exports;\n\t}\n\t// Create a new module (and put it into the cache)\n\tvar module = __webpack_module_cache__[moduleId] = {\n\t\t// no module.id needed\n\t\t// no module.loaded needed\n\t\texports: {}\n\t};\n\n\t// Execute the module function\n\t__webpack_modules__[moduleId](module, module.exports, __webpack_require__);\n\n\t// Return the exports of the module\n\treturn module.exports;\n}\n\n","// define getter functions for harmony exports\n__webpack_require__.d = (exports, definition) => {\n\tfor(var key in definition) {\n\t\tif(__webpack_require__.o(definition, key) && !__webpack_require__.o(exports, key)) {\n\t\t\tObject.defineProperty(exports, key, { enumerable: true, get: definition[key] });\n\t\t}\n\t}\n};","__webpack_require__.o = (obj, prop) => (Object.prototype.hasOwnProperty.call(obj, prop))","// define __esModule on exports\n__webpack_require__.r = (exports) => {\n\tif(typeof Symbol !== 'undefined' && Symbol.toStringTag) {\n\t\tObject.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });\n\t}\n\tObject.defineProperty(exports, '__esModule', { value: true });\n};","// Main Content Script\n// File: src/content/content.ts\nimport { TranscriptRecognition } from './speechRecognition';\nconsole.log('Content script loaded!');\nlet recognition = null;\nlet transcriptOverlay = null;\n// Create overlay UI for displaying transcript\nfunction createOverlay() {\n    if (transcriptOverlay)\n        return;\n    transcriptOverlay = document.createElement('div');\n    transcriptOverlay.id = 'transcript-overlay';\n    transcriptOverlay.style.cssText = `\n    position: fixed;\n    bottom: 20px;\n    left: 50%;\n    transform: translateX(-50%);\n    background: rgba(0, 0, 0, 0.85);\n    color: white;\n    padding: 16px 24px;\n    border-radius: 12px;\n    font-family: system-ui, -apple-system, sans-serif;\n    font-size: 16px;\n    max-width: 80%;\n    z-index: 999999;\n    box-shadow: 0 4px 20px rgba(0, 0, 0, 0.3);\n    display: none;\n  `;\n    // Status indicator\n    const statusDiv = document.createElement('div');\n    statusDiv.id = 'transcript-status';\n    statusDiv.style.cssText = `\n    font-size: 12px;\n    color: #4CAF50;\n    margin-bottom: 8px;\n    display: flex;\n    align-items: center;\n    gap: 6px;\n  `;\n    statusDiv.innerHTML = `\n    <span style=\"display: inline-block; width: 8px; height: 8px; background: #4CAF50; border-radius: 50%; animation: pulse 1.5s infinite;\"></span>\n    Listening...\n  `;\n    // Transcript text\n    const textDiv = document.createElement('div');\n    textDiv.id = 'transcript-text';\n    textDiv.style.cssText = `\n    line-height: 1.5;\n    min-height: 24px;\n  `;\n    textDiv.textContent = 'Say something...';\n    // Add animation keyframes\n    const style = document.createElement('style');\n    style.textContent = `\n    @keyframes pulse {\n      0%, 100% { opacity: 1; }\n      50% { opacity: 0.3; }\n    }\n  `;\n    document.head.appendChild(style);\n    transcriptOverlay.appendChild(statusDiv);\n    transcriptOverlay.appendChild(textDiv);\n    document.body.appendChild(transcriptOverlay);\n    console.log('Overlay created');\n}\nfunction updateTranscript(text, isFinal, confidence) {\n    if (!transcriptOverlay)\n        return;\n    const textDiv = document.getElementById('transcript-text');\n    if (!textDiv)\n        return;\n    // Color based on confidence\n    let color = '#ffffff';\n    if (confidence < 0.5) {\n        color = '#ff9800'; // Orange for low confidence\n    }\n    else if (confidence < 0.7) {\n        color = '#ffeb3b'; // Yellow for medium confidence\n    }\n    // Display text\n    if (isFinal) {\n        // Final result - append to existing text\n        const finalText = `<span style=\"color: ${color};\">${text}</span> `;\n        textDiv.innerHTML += finalText;\n        // Auto-scroll if too long\n        if (textDiv.textContent && textDiv.textContent.length > 200) {\n            const words = textDiv.textContent.split(' ');\n            textDiv.textContent = '...' + words.slice(-30).join(' ');\n        }\n    }\n    else {\n        // Interim result - show in gray\n        const existingFinal = textDiv.querySelector('span:last-of-type')?.previousSibling?.textContent || '';\n        textDiv.innerHTML = textDiv.innerHTML.split('<span style=\"color: #888;\">')[0] +\n            `<span style=\"color: #888;\">${text}</span>`;\n    }\n}\nfunction showOverlay() {\n    if (transcriptOverlay) {\n        transcriptOverlay.style.display = 'block';\n    }\n}\nfunction hideOverlay() {\n    if (transcriptOverlay) {\n        transcriptOverlay.style.display = 'none';\n    }\n}\n// Listen for messages from popup\nchrome.runtime.onMessage.addListener((message, sender, sendResponse) => {\n    console.log('Message received:', message);\n    if (message.action === 'start') {\n        if (!recognition) {\n            createOverlay();\n            recognition = new TranscriptRecognition((text, isFinal, confidence) => {\n                updateTranscript(text, isFinal, confidence);\n            });\n        }\n        recognition.start();\n        showOverlay();\n        sendResponse({ success: true, message: 'Started' });\n    }\n    if (message.action === 'stop') {\n        if (recognition) {\n            recognition.stop();\n            hideOverlay();\n        }\n        sendResponse({ success: true, message: 'Stopped' });\n    }\n    return true; // Keep message channel open for async response\n});\n"],"names":[],"sourceRoot":""}